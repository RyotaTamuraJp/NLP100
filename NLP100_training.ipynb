{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理100本ノック 2015 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第1章：準備運動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "00. 文字列の逆順\n",
    "文字列\"stressed\"の文字を逆に(末尾から先頭に向かって)並べた文字列を得よ.\n",
    "\"\"\"\n",
    "def reversion(string):\n",
    "    return \n",
    "\n",
    "# 以下いじらないこと\n",
    "string = \"stressed\"\n",
    "reversion(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ.\n",
    "\"\"\"\n",
    "def extraction_connection(string):\n",
    "    return \n",
    "\n",
    "# 以下いじらないこと\n",
    "string = \"パタトクカシーー\"\n",
    "reversion(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "02. 「パトカー」+「タクシー」=「パタトクカシーー」\n",
    "「パトカー」+「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ.\n",
    "\"\"\"\n",
    "def extraction_connection(str1, str2):\n",
    "    return \n",
    "\n",
    "# 以下いじらないこと\n",
    "str1 = \"パトカー\"\n",
    "str2 = \"タクシー\"\n",
    "extraction_connection(str1, str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "03. 円周率\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "という文を単語に分解し,各単語の(アルファベットの)文字数を先頭から出現順に並べたリストを作成せよ.\n",
    "\"\"\"\n",
    "def get_pi_number(text):\n",
    "    return\n",
    "\n",
    "# 以下いじらないこと\n",
    "text = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "get_pi_number(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "04. 元素記号\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "という文を単語に分解し,1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字,\n",
    "それ以外の単語は先頭に2文字を取り出し,取り出した文字列から単語の位置(先頭から何番目の単語か)への\n",
    "連想配列(辞書型もしくはマップ型)を作成せよ.\n",
    "\"\"\"\n",
    "def get_element_symbol(text):\n",
    "    return\n",
    "\n",
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "get_element_symbol(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram\n",
      "None\n",
      "単語tri-gram\n",
      "None\n",
      "文字bi-gram\n",
      "None\n",
      "文字tri-gram\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "05. n-gram\n",
    "与えられたシーケンス(文字列やリスト)からn-gramを作る関数を作成せよ.\n",
    "この関数を用い,\"I am an NLPer\"という文から単語bi-gram,文字bi-gramを得よ.\n",
    "\"\"\"\n",
    "# targetは文字列とリストを想定\n",
    "\n",
    "def n_gram(target, n):\n",
    "    return\n",
    "\n",
    "# 以下いじらないこと\n",
    "print(\"単語bi-gram\")\n",
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "target_token = text.split(\" \")\n",
    "print(n_gram(target_token, 2))\n",
    "\n",
    "print(\"単語tri-gram\")\n",
    "print(n_gram(target_token, 3))\n",
    "\n",
    "print(\"文字bi-gram\")\n",
    "target_character = text.replace(\" \", \"\")\n",
    "print(n_gram(target_character, 2))\n",
    "\n",
    "print(\"文字tri-gram\")\n",
    "print(n_gram(target_character, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合： None\n",
      "積集合： None\n",
      "差集合： None\n",
      "seがXに含まれる： None\n",
      "seがYに含まれる： None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "06. 集合\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を,それぞれ, XとYとして求め,XとYの和集合,\n",
    "積集合,差集合を求めよ.さらに,'se'というbi-gramがXおよびYに含まれるかどうかを調べよ.\n",
    "\"\"\"\n",
    "# 和集合\n",
    "def get_union(X, Y):\n",
    "    return\n",
    "\n",
    "# 積集合\n",
    "def get_intersection(X, Y):\n",
    "    return\n",
    "\n",
    "# 差集合\n",
    "def get_difference(X, Y):\n",
    "    return\n",
    "\n",
    "# \"se\"がX, Yに含まれているかチェック(boolで返してね)\n",
    "def check_set(gathering):\n",
    "    return\n",
    "\n",
    "# 以下いじらないこと\n",
    "text_x = \"paraparaparadise\"\n",
    "text_y = \"paragraph\"\n",
    "n = 2\n",
    "X = n_gram(text_x, n)\n",
    "Y = n_gram(text_y, n)\n",
    "print(\"和集合：\", get_union(X, Y))\n",
    "print(\"積集合：\", get_intersection(X, Y))\n",
    "print(\"差集合：\", get_difference(X, Y))\n",
    "print(\"seがXに含まれる：\", check_set(X))\n",
    "print(\"seがYに含まれる：\", check_set(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ.\n",
    "さらに,x=12, y=\"気温\", z=22.4として,実行結果を確認せよ.\n",
    "\"\"\"\n",
    "def get_template(x, y, z):\n",
    "    return\n",
    "\n",
    "# 以下いじらないこと\n",
    "x = 12\n",
    "y = \"気温\"\n",
    "z = 22.4\n",
    "print(get_template(x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力文字列： There is more to life than increasing its speed\n",
      "暗号化： None\n",
      "復号化： None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "08. 暗号文\n",
    "与えられた文字列の各文字を,以下の仕様で変換する関数cipherを実装せよ.\n",
    "　・英小文字ならば(219 - 文字コード)の文字に置換\n",
    "　・その他の文字はそのまま出力\n",
    "この関数を用い,英語のメッセージを暗号化・復号化せよ.\n",
    "\"\"\"\n",
    "def cipher(target_text):\n",
    "    return\n",
    "\n",
    "# 以下いじらないこと（入力文字列と復号化された文字列が同一でないといけない。）\n",
    "target_text = \"There is more to life than increasing its speed\"\n",
    "print(\"入力文字列：\", target_text)\n",
    "encryption = cipher(target_text)\n",
    "print(\"暗号化：\", encryption)\n",
    "decryption = cipher(encryption)\n",
    "print(\"復号化：\", decryption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "09. Typoglycemia\n",
    "スペースで区切られた単語列に対して,各単語の先頭と末尾の文字は残し,それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ.\n",
    "ただし,長さが4以下の単語は並び替えないこととする.\n",
    "適当な英語の文\n",
    "(例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\")\n",
    "を与え,その実行結果を確認せよ.\n",
    "\"\"\"\n",
    "# random_seedは123で固定します。\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "def typoglycemia(text):\n",
    "    return\n",
    "\n",
    "# 以下いじらないこと\n",
    "text = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(typoglycemia(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第2章：UNIXコマンドの基礎→Pandasとか言語処理の基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hightemp.txtは,日本の最高気温の記録を「都道府県」「地点」「℃」「日」のタブ区切り形式で格納したファイルである.以下の処理を行うプログラムを作成し,hightemp.txtを入力ファイルとして実行せよ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ここから先は\"corpus.zip\"をNLP100 のフォルダ内に解凍してから実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus/hightemp.txt がありました。次に進んでください。\n"
     ]
    }
   ],
   "source": [
    "# このセルは2章を行う場合必ず実行してください。\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "hightemp_path = \"corpus/hightemp.txt\"\n",
    "columns = [\"県\", \"市\", \"気温\", \"日付\"]\n",
    "hightemp_df = pd.read_table(hightemp_path, header=None)\n",
    "hightemp_df.columns = columns\n",
    "if os.path.exists(hightemp_path):\n",
    "    print(hightemp_path, \"がありました。次に進んでください。\")\n",
    "else:\n",
    "    print(\"警告！\")\n",
    "    print(hightemp_path, \"がありません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>県</th>\n",
       "      <th>市</th>\n",
       "      <th>気温</th>\n",
       "      <th>日付</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>高知県</td>\n",
       "      <td>江川崎</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2013-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>埼玉県</td>\n",
       "      <td>熊谷</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2007-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>岐阜県</td>\n",
       "      <td>多治見</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2007-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>山形県</td>\n",
       "      <td>山形</td>\n",
       "      <td>40.8</td>\n",
       "      <td>1933-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>山梨県</td>\n",
       "      <td>甲府</td>\n",
       "      <td>40.7</td>\n",
       "      <td>2013-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>和歌山県</td>\n",
       "      <td>かつらぎ</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1994-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>静岡県</td>\n",
       "      <td>天竜</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1994-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>山梨県</td>\n",
       "      <td>勝沼</td>\n",
       "      <td>40.5</td>\n",
       "      <td>2013-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>埼玉県</td>\n",
       "      <td>越谷</td>\n",
       "      <td>40.4</td>\n",
       "      <td>2007-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>群馬県</td>\n",
       "      <td>館林</td>\n",
       "      <td>40.3</td>\n",
       "      <td>2007-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>群馬県</td>\n",
       "      <td>上里見</td>\n",
       "      <td>40.3</td>\n",
       "      <td>1998-07-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>愛知県</td>\n",
       "      <td>愛西</td>\n",
       "      <td>40.3</td>\n",
       "      <td>1994-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>千葉県</td>\n",
       "      <td>牛久</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2004-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>静岡県</td>\n",
       "      <td>佐久間</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2001-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>愛媛県</td>\n",
       "      <td>宇和島</td>\n",
       "      <td>40.2</td>\n",
       "      <td>1927-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>山形県</td>\n",
       "      <td>酒田</td>\n",
       "      <td>40.1</td>\n",
       "      <td>1978-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>岐阜県</td>\n",
       "      <td>美濃</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2007-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>群馬県</td>\n",
       "      <td>前橋</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2001-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>千葉県</td>\n",
       "      <td>茂原</td>\n",
       "      <td>39.9</td>\n",
       "      <td>2013-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>埼玉県</td>\n",
       "      <td>鳩山</td>\n",
       "      <td>39.9</td>\n",
       "      <td>1997-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>大阪府</td>\n",
       "      <td>豊中</td>\n",
       "      <td>39.9</td>\n",
       "      <td>1994-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>山梨県</td>\n",
       "      <td>大月</td>\n",
       "      <td>39.9</td>\n",
       "      <td>1990-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>山形県</td>\n",
       "      <td>鶴岡</td>\n",
       "      <td>39.9</td>\n",
       "      <td>1978-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>愛知県</td>\n",
       "      <td>名古屋</td>\n",
       "      <td>39.9</td>\n",
       "      <td>1942-08-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       県     市    気温          日付\n",
       "0    高知県   江川崎  41.0  2013-08-12\n",
       "1    埼玉県    熊谷  40.9  2007-08-16\n",
       "2    岐阜県   多治見  40.9  2007-08-16\n",
       "3    山形県    山形  40.8  1933-07-25\n",
       "4    山梨県    甲府  40.7  2013-08-10\n",
       "5   和歌山県  かつらぎ  40.6  1994-08-08\n",
       "6    静岡県    天竜  40.6  1994-08-04\n",
       "7    山梨県    勝沼  40.5  2013-08-10\n",
       "8    埼玉県    越谷  40.4  2007-08-16\n",
       "9    群馬県    館林  40.3  2007-08-16\n",
       "10   群馬県   上里見  40.3  1998-07-04\n",
       "11   愛知県    愛西  40.3  1994-08-05\n",
       "12   千葉県    牛久  40.2  2004-07-20\n",
       "13   静岡県   佐久間  40.2  2001-07-24\n",
       "14   愛媛県   宇和島  40.2  1927-07-22\n",
       "15   山形県    酒田  40.1  1978-08-03\n",
       "16   岐阜県    美濃  40.0  2007-08-16\n",
       "17   群馬県    前橋  40.0  2001-07-24\n",
       "18   千葉県    茂原  39.9  2013-08-11\n",
       "19   埼玉県    鳩山  39.9  1997-07-05\n",
       "20   大阪府    豊中  39.9  1994-08-08\n",
       "21   山梨県    大月  39.9  1990-07-19\n",
       "22   山形県    鶴岡  39.9  1978-08-03\n",
       "23   愛知県   名古屋  39.9  1942-08-02"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hightemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "10. 行数のカウント\n",
    "Pandasのデータフレームの行数をカウントせよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def get_row_count(df):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "print(get_row_count(hightemp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文： この\t間\tにタブがある。\n",
      "置換結果： None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "11. タブをスペースに置換\n",
    "タブ1文字につき半角スペース1文字に置換せよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def tab2space(text):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "text = \"この\\t間\\tにタブがある。\"\n",
    "print(\"原文：\", text)\n",
    "print(\"置換結果：\", tab2space(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1：\n",
      " \n",
      "col2：\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "12. 1列目をcol1.txtに,2列目をcol2.txtに保存\n",
    "各行の1列目だけを抜き出したものをcol1.txtに,\n",
    "2列目だけを抜き出したものをcol2.txtとしてファイルに保存せよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 返り値不要。指定した列をテキストファイルに保存すること。\n",
    "# コード書いたらpassは消すこと。\n",
    "\n",
    "def column2txtfile(df, column_num, save_text_name):\n",
    "    pass\n",
    "\n",
    "# テキストファイルを指定して読み込む。\n",
    "#return_text(文字列)に指定したfile_pathの内容を保存し、returnする。\n",
    "def read_text(file_path):\n",
    "    return_text = \"\"\n",
    "    return return_text\n",
    "\n",
    "# 以下いじらない\n",
    "save_text_name_1 = \"./result/Q12/col1.txt\"\n",
    "save_text_name_2 = \"./result/Q12/col2.txt\"\n",
    "column2txtfile(hightemp_df, 0, save_text_name_1)\n",
    "column2txtfile(hightemp_df, 1, save_text_name_2)\n",
    "print(\"col1：\\n\", read_text(save_text_name_1))\n",
    "print(\"col2：\\n\", read_text(save_text_name_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "マージされたテキスト\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "13. col1.txtとcol2.txtをマージ\n",
    "12で作ったcol1.txtとcol2.txtを結合し,\n",
    "元のファイルの1列目と2列目をタブ区切りで並べたテキストファイルを作成せよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 2つのテキストファイルの内容を入力とする。\n",
    "# テキストファイルの読み込みはNo.12のread_textを利用する。\n",
    "# 返り値なしで内容をマージしたテキストファイルを作成すること。\n",
    "\n",
    "def merge_text(text1, text2, save_text_name):\n",
    "    pass\n",
    "\n",
    "# 以下いじらない\n",
    "save_text_name_1 = \"./result/12_col1.txt\"\n",
    "save_text_name_2 = \"./result/12_col2.txt\"\n",
    "text1 = read_text(save_text_name_1)\n",
    "text2 = read_text(save_text_name_2)\n",
    "save_text_name_merge = \"./result/Q13/merge.txt\"\n",
    "merge_text(text1, text2, save_text_name_merge)\n",
    "print(\"マージされたテキスト\\n\", read_text(save_text_name_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "指定したn= 3\n",
      "None\n",
      "----------------------------------------\n",
      "指定したn= 5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "14. 先頭からN行を出力\n",
    "任意の自然数Nを受け取り,入力のうち先頭のN行だけを表示せよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def get_n_row(df, n):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "n = 3\n",
    "print(\"指定したn=\", n)\n",
    "print(get_n_row(hightemp_df, n))\n",
    "print(\"--\"*20)\n",
    "n = 5\n",
    "print(\"指定したn=\", n)\n",
    "print(get_n_row(hightemp_df, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "指定したn= 3\n",
      "None\n",
      "----------------------------------------\n",
      "指定したn= 5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "15. 末尾のN行を出力\n",
    "任意の自然数Nを受け取り,入力のうち末尾のN行だけを表示せよ.\n",
    "\"\"\"\n",
    "def get_n_row_reverce_order(df, n):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "n = 3\n",
    "print(\"指定したn=\", n)\n",
    "print(get_n_row_reverce_order(hightemp_df, n))\n",
    "print(\"--\"*20)\n",
    "n = 5\n",
    "print(\"指定したn=\", n)\n",
    "print(get_n_row_reverce_order(hightemp_df, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全ての行が出力されていません。\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "16. ファイルをN分割する\n",
    "自然数Nをコマンドライン引数などの手段で受け取り,\n",
    "入力のファイルを行単位でN分割せよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Pandasのデータフレームを行ごとにテキストファイルを作成。\n",
    "# save_directoryで指定されたフォルダにファイルを保存する。\n",
    "# 保存するファイル名は行の番号になっていること。\n",
    "# 返り値はない。\n",
    "\n",
    "def row2textfile(df, save_directory):\n",
    "    pass\n",
    "\n",
    "# 以下いじらない\n",
    "save_directory = \"./result/Q16/\"\n",
    "row2textfile(hightemp_df, save_directory)\n",
    "import glob\n",
    "import os\n",
    "file_path = glob.glob(save_directory + \"*\")\n",
    "if len(file_path) != len(hightemp_df):\n",
    "    print(\"全ての行が出力されていません。\")\n",
    "else:\n",
    "    for f in file_path:\n",
    "        text = read_text(f)\n",
    "        file_name = os.path.basename(f)\n",
    "        print(\"{0}：{1}\".format(file_name, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "17. 1列目の文字列の異なり\n",
    "1列目の文字列の種類(異なる文字列の集合)を求めよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "def get_unique_set(df):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "print(get_unique_set(hightemp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "18. 各行を3列目の数値の降順にソート\n",
    "各行を3列目の数値の逆順で整列せよ(注意: 各行の内容は変更せずに並び替えよ).\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# n_colで指定した列の値で降順にソート\n",
    "\n",
    "def sort_df(df, n_col):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "n_col = 3\n",
    "sort_df(hightemp_df, n_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列が追加されていません。\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "19. 各行の1列目の文字列の出現頻度を求め,出現頻度の高い順に並べる\n",
    "各行の1列目の文字列の出現頻度を求め,その高い順に並べて表示せよ.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 各行のn列目の文字列の出現頻度を求め、元のデータフレームに出現頻度の列を追加する関数を作成すること。\n",
    "\n",
    "def add_frequency(df, n_col):\n",
    "    return df\n",
    "\n",
    "# 以下いじらない\n",
    "new_df = add_frequency(hightemp_df, 1)\n",
    "if len(new_df.columns) < 5:\n",
    "    print(\"列が追加されていません。\")\n",
    "elif len(new_df.columns) > 5:\n",
    "    print(\"列が多すぎます。\")\n",
    "else:\n",
    "    sort_df(new_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第3章: 正規表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipediaの記事を以下のフォーマットで書き出したファイルenwiki-20150112-400-r10-105752.txtがcorpus内にある.\n",
    "- 1行に1記事の情報がJSON形式で格納される\n",
    "- 各行には記事名が\"title\"キーに,記事本文が\"text\"キーの辞書オブジェクトに格納され,そのオブジェクトがJSON形式で書き出される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ここから先は\"corpus.zip\"をNLP100 のフォルダ内に解凍してから実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "20. JSONデータの読み込み\n",
    "Wikipedia記事のJSONファイルを読み込み,「イギリス」に関する記事本文を表示せよ.\n",
    "問題21-29では,ここで抽出した記事本文に対して実行せよ.\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "\n",
    "# json_pathで指定したjsonファイルを読み込み、json内の\"title\"キーと特定のkey_wordの値が一致したものをreturnする。\n",
    "# ※ファイルを一気に読み込むとメモリをバク食いするためおすすめしない。\n",
    "\n",
    "def search_json(json_path, key_word):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    for key in british_article.keys():\n",
    "        print(\"{0}:{1}\".format(key, british_article[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "21. カテゴリ名を含む行を抽出\n",
    "記事中でカテゴリ名を宣言している行を抽出せよ.\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# 前問の20で出力したイギリスの記事の中に\"[[Category:XXX]]\"という箇所が複数ある。\n",
    "# それらを全て抽出し、category_listに格納してreturnすること。\n",
    "# ヒント：全部で8つ\n",
    "\n",
    "def extract_category_lines(article):\n",
    "    category_list = []\n",
    "    return category_list\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    category_list = extract_category_lines(british_article)\n",
    "    for category in category_list:\n",
    "        print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "22. カテゴリ名の抽出\n",
    "記事のカテゴリ名を(行単位ではなく名前で)抽出せよ.\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# 21の結果を用いることを想定する。\n",
    "# 正規表現を用いてカテゴリ名のみを抽出すること。\n",
    "# 入力は\"[[Category:XXX]]\"であり、出力は\"XXX\"である。\n",
    "\n",
    "def extract_category_name(category_line):\n",
    "    return\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    category_list = extract_category_lines(british_article)\n",
    "    for i, category in enumerate(category_list):\n",
    "        print(\"Category{0}:{1}\".format(i, extract_category_name(category)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "23. セクション構造\n",
    "記事中に含まれるセクション名とそのレベル(例えば\"== セクション名 ==\"なら1)を表示せよ.\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# wikipediaでは\"== セクション名 ==\"のように2つ以上の\"=\"で文字を囲むとセクション名になる。\n",
    "# \"== XXX ==\"はレベル1でセクション名はXXX、\"=== YYY ===\"はレベル2でセクション名はYYYである。\n",
    "# レベルの最大値は4である。\n",
    "# セクション名とレベルを問21で出力したイギリスの記事から抽出する。\n",
    "# section_list内に[セクション名, レベル]のリストを格納して出力すること。\n",
    "\n",
    "def extract_section_name_and_level(article):\n",
    "    section_list = []\n",
    "    return section_list\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    section_list = extract_section_name_and_level(british_article)\n",
    "    for section in section_list:\n",
    "        sec_name, level = section\n",
    "        indent = \"\\t\" * (level - 1)\n",
    "        print(\"{0}{1}({2})\".format(indent, sec_name, level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "24. ファイル参照の抽出\n",
    "記事から参照されているメディアファイルをすべて抜き出せ.\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# wikipediaでは\"[[ファイル:メディアファイル名|thumb|説明文]]\"のようにすることでメディアファイルを参照可能。\n",
    "# 問21で出力したイギリスの記事からメディアファイル名を全て抽出する。\n",
    "# media_name_list(リスト型)にメディアファイル名を格納すること。\n",
    "\n",
    "def extract_media_name(article):\n",
    "    media_name_list = []\n",
    "    return media_name_list\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    media_name_list = extract_media_name(british_article)\n",
    "    for i, media_name in enumerate(media_name_list):\n",
    "        print(\"{0}:{1}\".format(i, media_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "25. テンプレートの抽出\n",
    "記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し,辞書オブジェクトとして格納せよ.\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# 以下のリンクは日本語Wikipediaの基礎情報_国のテンプレートの説明である。\n",
    "# https://ja.wikipedia.org/wiki/Template:%E5%9F%BA%E7%A4%8E%E6%83%85%E5%A0%B1_%E5%9B%BD\n",
    "# 問21のイギリスの記事から基礎情報のフィールド名とその値をbasic_info(辞書型)で格納すること。\n",
    "\n",
    "def extract_basic_information(article):\n",
    "    basic_info = {}\n",
    "    return basic_info\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    basic_info = extract_basic_information(british_article)\n",
    "    for key in basic_info:\n",
    "        print(\"{0}:{1}\".format(key, basic_info[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "26. 強調マークアップの除去\n",
    "25の処理時に,テンプレートの値からMediaWikiの強調マークアップ\n",
    "(弱い強調,強調,強い強調のすべて)を除去してテキストに変換せよ\n",
    "(参考: マークアップ早見表　https://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8).\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# 強調表現（''他との区別''、'''強調'''、'''''斜体と強調'''''）となるシングルクォーテーションを削除すること\n",
    "# ただし、強調表現以外のシングルクォーテーションを削除してはいけない。\n",
    "# 入力は25の結果え得られた基礎情報を格納した辞書である。\n",
    "# 結果はremove_emphasis_dict（辞書型）に格納してreturnすること。\n",
    "\n",
    "def remove_emphasis(basic_info_dict):\n",
    "    remove_emphasis_dict = {}\n",
    "    return remove_emphasis_dict\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    basic_info = extract_basic_information(british_article)\n",
    "    remove_emphasis_dict = remove_emphasis(basic_info)\n",
    "    for key in remove_emphasis_dict:\n",
    "        print(\"{0}:{1}\".format(key, remove_emphasis_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "27. 内部リンクの除去\n",
    "26の処理に加えて,テンプレートの値からMediaWikiの内部リンクマークアップを除去し,テキストに変換せよ.\n",
    "(参考: マークアップ早見表　https://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8).\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# 内部リンクの書き方は以下の3種類ある。\n",
    "# [[記事名]], [[記事名|表示文字]], [[記事名#節名|表示文字]]\n",
    "# 問26の結果を用いて内部リンクのみを除去すること。\n",
    "# 入力は問26のremove_emphasis_dictである。\n",
    "# 出力はremove_link_dict（辞書型）に格納してreturnすること\n",
    "\n",
    "def remove_internal_link(remove_emphasis_dict):\n",
    "    remove_link_dict = {}\n",
    "    return remove_link_dict\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    basic_info = extract_basic_information(british_article)\n",
    "    remove_emphasis_dict = remove_emphasis(basic_info)\n",
    "    remove_link_dict = remove_internal_link(remove_emphasis_dict)\n",
    "    for key in remove_link_dict:\n",
    "        print(\"{0}:{1}\".format(key, remove_link_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "28. MediaWikiマークアップの除去\n",
    "27の処理に加えて,テンプレートの値からMediaWikiマークアップを可能な限り除去し,国の基本情報を整形せよ.\n",
    "(参考: マークアップ早見表　https://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8).\n",
    "\"\"\"\n",
    "import re\n",
    "# マークアップ早見表を参考に可能な限りマークアップ表現を削除すること。\n",
    "# 問27の結果を用いることを想定する。\n",
    "# 出力はremove_markup_dictに格納してreturnすること。\n",
    "def remove_markup(remove_link_dict):\n",
    "    remove_markup_dict = {}\n",
    "    return remove_markup_dict\n",
    "\n",
    "# 以下いじらない\n",
    "json_path = \"./corpus/jawiki-country.json\"\n",
    "key_word = \"イギリス\"\n",
    "if not os.path.exists(json_path):\n",
    "    print(json_path, \"が存在しません。\")\n",
    "else:\n",
    "    british_article = search_json(json_path, key_word)\n",
    "    basic_info = extract_basic_information(british_article)\n",
    "    remove_emphasis_dict = remove_emphasis(basic_info)\n",
    "    remove_link_dict = remove_internal_link(remove_emphasis_dict)\n",
    "    remove_markup_dict = remove_markup(remove_link_dict)\n",
    "    for key in remove_markup_dict:\n",
    "        print(\"{0}:{1}\".format(key, remove_markup_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "29. 国旗画像のURLを取得する\n",
    "テンプレートの内容を利用し,国旗画像のURLを取得せよ.\n",
    "(ヒント: MediaWiki APIのimageinfoを呼び出して,ファイル参照をURLに変換すればよい)\n",
    "\"\"\"\n",
    "import re\n",
    "import urllib\n",
    "import json\n",
    "\n",
    "# 問28の結果を用いることを想定する。\n",
    "# 本問題ではurllib.parse, urllib.requestを用いる\n",
    "# 入力は基礎情報内の国旗画像の値である。\n",
    "# その値を用いてMediaWiki APIにRequestを送信する関数を作成する。\n",
    "# MediaWiki APIからデータをjsonとして受信すること。\n",
    "# 受信したデータから画像のURLだけを抽出してimage_url(string)としてreturnすること。\n",
    "\n",
    "def get_image_url(image_value):\n",
    "    image_url = \"\"\n",
    "    return image_url\n",
    "\n",
    "# 以下いじらないこと\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
